{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe6d0dcd",
   "metadata": {},
   "source": [
    "# nnUnetV2 data processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23537b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "478e811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create nnUNet dataset root directories\n",
    "root_dir = \"nnunet_data\"\n",
    "os.makedirs(os.path.join(root_dir, \"nnUNet_raw\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(root_dir, \"nnUNet_preprocessed\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(root_dir, \"nnUNet_results\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b303aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset specific dataset and move data into train and test folders\n",
    "# train folder contains both\n",
    "dataset_dir = \"Dataset001_PancreasSegClassification\"\n",
    "dataset_root = os.path.join(root_dir, \"nnUNet_raw\", dataset_dir)\n",
    "os.makedirs(dataset_root, exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, \"imagesTr\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, \"imagesTs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, \"labelsTr\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, \"labelsTs\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07cf7d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the subtypes before converting file naming\n",
    "import json\n",
    "labels = {}\n",
    "\n",
    "train_dir = \"raw_data/train\"\n",
    "validation_dir = \"raw_data/validation\"\n",
    "\n",
    "# subtype 0\n",
    "for fname in os.listdir(os.path.join(train_dir, 'subtype0')):\n",
    "    if fname.endswith(\"_0000.nii.gz\"):\n",
    "        head, subtype, fid, ending = fname.split(\"_\")\n",
    "        labels['_'.join([head, fid, ending])] = {\"subtype\": 0, \"split\": \"train\"}\n",
    "for fname in os.listdir(os.path.join(validation_dir, 'subtype0')):\n",
    "    if fname.endswith(\"_0000.nii.gz\"):\n",
    "        head, subtype, fid, ending = fname.split(\"_\")\n",
    "        labels['_'.join([head, fid, ending])] = {\"subtype\": 0, \"split\": \"validation\"}\n",
    "\n",
    "# subtype 1\n",
    "for fname in os.listdir(os.path.join(train_dir, 'subtype1')):\n",
    "    if fname.endswith(\"_0000.nii.gz\"):\n",
    "        head, subtype, fid, ending = fname.split(\"_\")\n",
    "        labels['_'.join([head, fid, ending])] = {\"subtype\": 1, \"split\": \"train\"}\n",
    "for fname in os.listdir(os.path.join(validation_dir, 'subtype1')):\n",
    "    if fname.endswith(\"_0000.nii.gz\"):\n",
    "        head, subtype, fid, ending = fname.split(\"_\")\n",
    "        labels['_'.join([head, fid, ending])] = {\"subtype\": 1, \"split\": \"validation\"}\n",
    "\n",
    "\n",
    "# subtype 2\n",
    "for fname in os.listdir(os.path.join(train_dir, 'subtype2')):\n",
    "    if fname.endswith(\"_0000.nii.gz\"):\n",
    "        head, subtype, fid, ending = fname.split(\"_\")\n",
    "        labels['_'.join([head, fid, ending])] = {\"subtype\": 2, \"split\": \"train\"}\n",
    "for fname in os.listdir(os.path.join(validation_dir, 'subtype2')):\n",
    "    if fname.endswith(\"_0000.nii.gz\"):\n",
    "        head, subtype, fid, ending = fname.split(\"_\")\n",
    "        labels['_'.join([head, fid, ending])] = {\"subtype\": 2, \"split\": \"validation\"}\n",
    "\n",
    "\n",
    "assert len(labels) == 288, \"Length of should be the same before and after conversion.\"\n",
    "\n",
    "with open(os.path.join(dataset_root, \"data_split.json\"), \"w\") as jsonfile:\n",
    "    json.dump(labels, jsonfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c1e3d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset.json for the model\n",
    "from nnunetv2.dataset_conversion.generate_dataset_json import generate_dataset_json\n",
    "\n",
    "generate_dataset_json(\n",
    "    output_folder=str(dataset_root),\n",
    "    channel_names={0: \"CT\"},\n",
    "    labels={\n",
    "        'background': 0,\n",
    "        'pancreas': 1,\n",
    "        'lesion': 2,\n",
    "    },\n",
    "    num_training_cases=252,\n",
    "    file_ending='.nii.gz',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cbe4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertion of the filename and move the files over\n",
    "import shutil\n",
    "tr_source_dirs = [os.path.join(\"raw_data/train\", f\"subtype{i}\") for i in (0,1,2)]\n",
    "val_source_dirs = [os.path.join(\"raw_data/validation\", f\"subtype{i}\") for i in (0,1,2)]\n",
    "tr_images_dir = os.path.join(dataset_root, \"imagesTr\")\n",
    "tr_labels_dir = os.path.join(dataset_root, \"labelsTr\")\n",
    "val_images_dir = os.path.join(dataset_root, \"imagesTs\")\n",
    "val_labels_dir = os.path.join(dataset_root, \"labelsTs\")\n",
    "\n",
    "for sd in tr_source_dirs:\n",
    "    for source_file in os.listdir(sd):\n",
    "        source_path = os.path.join(sd, source_file)\n",
    "        if source_file.endswith(\"_0000.nii.gz\"): # image files\n",
    "            head, subtype, fid, ending = source_file.split(\"_\")\n",
    "            new_filename = f\"{head}_{fid}_{ending}\"\n",
    "            dest_path = os.path.join(tr_images_dir, new_filename)\n",
    "            shutil.copy2(source_path, dest_path)\n",
    "        elif source_file.endswith(\".nii.gz\"): # label files\n",
    "            head, subtype, ending = source_file.split(\"_\")\n",
    "            new_filename = f\"{head}_{ending}\"\n",
    "            dest_path = os.path.join(tr_labels_dir, new_filename)\n",
    "            shutil.copy2(source_path, dest_path)\n",
    "\n",
    "for sd in val_source_dirs:\n",
    "    for source_file in os.listdir(sd):\n",
    "        source_path = os.path.join(sd, source_file)\n",
    "        if source_file.endswith(\"_0000.nii.gz\"): # image files\n",
    "            head, subtype, fid, ending = source_file.split(\"_\")\n",
    "            new_filename = f\"{head}_{fid}_{ending}\"\n",
    "            dest_path = os.path.join(val_images_dir, new_filename)\n",
    "            shutil.copy2(source_path, dest_path)\n",
    "        elif source_file.endswith(\".nii.gz\"): # label files\n",
    "            head, subtype, ending = source_file.split(\"_\")\n",
    "            new_filename = f\"{head}_{ending}\"\n",
    "            dest_path = os.path.join(val_labels_dir, new_filename)\n",
    "            shutil.copy2(source_path, dest_path)\n",
    "\n",
    "\n",
    "assert len(os.listdir(tr_images_dir)) == 252, \"Number of images in imagesTr should be 252.\"\n",
    "assert len(os.listdir(tr_labels_dir)) == 252, \"Number of labels in labelsTr should be 252.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cedcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy test files over to the folder\n",
    "# import shutil\n",
    "# test_dir = \"raw_data/test\"\n",
    "# for fname in os.listdir(test_dir):\n",
    "#     if fname.endswith(\"_0000.nii.gz\"):\n",
    "#         source_path = os.path.join(test_dir, fname)\n",
    "#         dest_path = os.path.join(dataset_root, \"imagesTs\", fname)\n",
    "#         # nnunet_data/nnUNet_raw/Dataset001_PancreasSegClassification/imagesTs\n",
    "#         shutil.copy2(source_path, dest_path)\n",
    "# assert len(os.listdir(os.path.join(dataset_root, \"imagesTs\"))) == 72, \"Number of images in imagesTs should be 96.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b276d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: [0. 1. 2.]\n",
      "Data type: float64\n"
     ]
    }
   ],
   "source": [
    "# make sure the segmentation labels are in correct type\n",
    "import nibabel as nib\n",
    "\n",
    "labels_dirs = [tr_labels_dir, val_labels_dir]\n",
    "\n",
    "for labels_dir in labels_dirs:\n",
    "    for label_file in os.listdir(labels_dir):\n",
    "        label_path = os.path.join(labels_dir, label_file)\n",
    "        img = nib.load(label_path)\n",
    "        data = img.get_fdata()\n",
    "\n",
    "        # Check if the data type is not int16\n",
    "        if data.dtype != np.int16:\n",
    "            # print(f\"Converting {label_file} to int16.\")\n",
    "            data = data.astype(np.int16)\n",
    "            new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "            new_img.set_data_dtype(np.int16)\n",
    "            nib.save(new_img, label_path)\n",
    "\n",
    "# check on label\n",
    "img = nib.load('/mnt/data/gpu-server/m31_nnUnet/nnunet_data/nnUNet_raw/Dataset001_PancreasSegClassification/labelsTr/quiz_544.nii.gz')\n",
    "print('Unique values:', np.unique(img.get_fdata()))\n",
    "print('Data type:', img.get_fdata().dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bff23ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDOUT: Fingerprint extraction...\n",
      "Dataset001_PancreasSegClassification\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "Experiment planning...\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [ 59. 118. 181.], 3d_lowres: [59, 118, 181]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 132, 'patch_size': (np.int64(128), np.int64(192)), 'median_image_size_in_voxels': array([118., 181.]), 'spacing': array([0.73046875, 0.73046875]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 3, 'patch_size': (np.int64(64), np.int64(128), np.int64(192)), 'median_image_size_in_voxels': array([ 59., 118., 181.]), 'spacing': array([2.        , 0.73046875, 0.73046875]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((1, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (1, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to /mnt/data/gpu-server/m31_nnUnet/nnunet_data/nnUNet_preprocessed/Dataset001_PancreasSegClassification/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset001_PancreasSegClassification\n",
      "Configuration: 3d_fullres...\n",
      "\n",
      "STDERR: \n",
      "  0%|          | 0/252 [00:00<?, ?it/s]\n",
      "  0%|          | 1/252 [00:01<07:36,  1.82s/it]\n",
      "  1%|          | 3/252 [00:01<02:06,  1.96it/s]\n",
      "  4%|▍         | 10/252 [00:02<00:29,  8.33it/s]\n",
      "  8%|▊         | 20/252 [00:02<00:12, 19.13it/s]\n",
      " 11%|█         | 27/252 [00:02<00:08, 26.42it/s]\n",
      " 13%|█▎        | 34/252 [00:02<00:06, 33.79it/s]\n",
      " 16%|█▋        | 41/252 [00:02<00:05, 40.70it/s]\n",
      " 20%|██        | 51/252 [00:02<00:03, 53.52it/s]\n",
      " 23%|██▎       | 59/252 [00:02<00:03, 59.68it/s]\n",
      " 27%|██▋       | 68/252 [00:02<00:02, 67.16it/s]\n",
      " 31%|███▏      | 79/252 [00:02<00:02, 78.25it/s]\n",
      " 35%|███▍      | 88/252 [00:02<00:02, 81.22it/s]\n",
      " 38%|███▊      | 97/252 [00:03<00:01, 83.51it/s]\n",
      " 43%|████▎     | 109/252 [00:03<00:01, 93.73it/s]\n",
      " 48%|████▊     | 120/252 [00:03<00:01, 98.07it/s]\n",
      " 52%|█████▏    | 131/252 [00:03<00:01, 78.28it/s]\n",
      " 56%|█████▌    | 140/252 [00:03<00:01, 80.69it/s]\n",
      " 59%|█████▉    | 149/252 [00:03<00:01, 82.97it/s]\n",
      " 63%|██████▎   | 158/252 [00:03<00:01, 84.39it/s]\n",
      " 66%|██████▋   | 167/252 [00:03<00:01, 66.89it/s]\n",
      " 69%|██████▉   | 175/252 [00:04<00:01, 69.48it/s]\n",
      " 74%|███████▍  | 186/252 [00:04<00:00, 79.21it/s]\n",
      " 78%|███████▊  | 197/252 [00:04<00:00, 86.73it/s]\n",
      " 82%|████████▏ | 207/252 [00:04<00:00, 89.90it/s]\n",
      " 87%|████████▋ | 219/252 [00:04<00:00, 98.15it/s]\n",
      " 91%|█████████▏| 230/252 [00:04<00:00, 100.82it/s]\n",
      " 96%|█████████▌| 241/252 [00:04<00:00, 103.22it/s]\n",
      "100%|██████████| 252/252 [00:04<00:00, 105.11it/s]\n",
      "100%|██████████| 252/252 [00:04<00:00, 51.83it/s] \n",
      "\n",
      "  0%|          | 0/252 [00:00<?, ?it/s]\n",
      "  0%|          | 1/252 [00:02<09:15,  2.21s/it]\n",
      "  1%|          | 2/252 [00:02<04:17,  1.03s/it]\n",
      "  1%|          | 3/252 [00:02<02:53,  1.44it/s]\n",
      "  2%|▏         | 4/252 [00:02<01:54,  2.17it/s]\n",
      "  2%|▏         | 5/252 [00:03<01:30,  2.72it/s]\n",
      "  3%|▎         | 7/252 [00:03<01:27,  2.79it/s]\n",
      "  3%|▎         | 8/252 [00:04<01:23,  2.91it/s]\n",
      "  4%|▎         | 9/252 [00:04<01:07,  3.62it/s]\n",
      "  4%|▍         | 10/252 [00:04<00:54,  4.41it/s]\n",
      "  4%|▍         | 11/252 [00:04<00:45,  5.25it/s]\n",
      "  5%|▌         | 13/252 [00:04<00:52,  4.60it/s]\n",
      "  6%|▋         | 16/252 [00:04<00:30,  7.86it/s]\n",
      "  7%|▋         | 18/252 [00:05<00:42,  5.48it/s]\n",
      "  8%|▊         | 20/252 [00:06<00:47,  4.91it/s]\n",
      "  9%|▊         | 22/252 [00:06<00:35,  6.39it/s]\n",
      " 10%|▉         | 24/252 [00:06<00:49,  4.63it/s]\n",
      " 10%|▉         | 25/252 [00:07<00:52,  4.33it/s]\n",
      " 10%|█         | 26/252 [00:07<00:55,  4.08it/s]\n",
      " 11%|█         | 28/252 [00:07<00:42,  5.21it/s]\n",
      " 12%|█▏        | 29/252 [00:07<00:38,  5.78it/s]\n",
      " 12%|█▏        | 30/252 [00:08<00:49,  4.44it/s]\n",
      " 13%|█▎        | 32/252 [00:08<00:51,  4.25it/s]\n",
      " 13%|█▎        | 33/252 [00:08<00:45,  4.87it/s]\n",
      " 13%|█▎        | 34/252 [00:09<00:49,  4.38it/s]\n",
      " 14%|█▍        | 36/252 [00:09<00:33,  6.41it/s]\n",
      " 15%|█▌        | 38/252 [00:09<00:32,  6.50it/s]\n",
      " 15%|█▌        | 39/252 [00:09<00:48,  4.42it/s]\n",
      " 16%|█▌        | 40/252 [00:10<00:41,  5.07it/s]\n",
      " 17%|█▋        | 42/252 [00:10<00:37,  5.59it/s]\n",
      " 17%|█▋        | 43/252 [00:10<00:52,  4.00it/s]\n",
      " 18%|█▊        | 46/252 [00:11<00:33,  6.21it/s]\n",
      " 19%|█▊        | 47/252 [00:11<00:42,  4.85it/s]\n",
      " 19%|█▉        | 48/252 [00:11<00:37,  5.44it/s]\n",
      " 19%|█▉        | 49/252 [00:11<00:42,  4.74it/s]\n",
      " 20%|█▉        | 50/252 [00:12<00:52,  3.87it/s]\n",
      " 21%|██        | 52/252 [00:12<00:46,  4.27it/s]\n",
      " 21%|██        | 53/252 [00:12<00:45,  4.42it/s]\n",
      " 21%|██▏       | 54/252 [00:13<00:53,  3.71it/s]\n",
      " 22%|██▏       | 55/252 [00:13<00:54,  3.60it/s]\n",
      " 22%|██▏       | 56/252 [00:13<00:45,  4.36it/s]\n",
      " 23%|██▎       | 58/252 [00:14<00:54,  3.54it/s]\n",
      " 24%|██▍       | 61/252 [00:14<00:37,  5.14it/s]\n",
      " 25%|██▍       | 62/252 [00:14<00:40,  4.67it/s]\n",
      " 25%|██▌       | 63/252 [00:15<00:35,  5.26it/s]\n",
      " 25%|██▌       | 64/252 [00:15<00:31,  5.90it/s]\n",
      " 26%|██▌       | 65/252 [00:15<00:33,  5.65it/s]\n",
      " 26%|██▌       | 66/252 [00:15<00:34,  5.46it/s]\n",
      " 27%|██▋       | 69/252 [00:16<00:35,  5.20it/s]\n",
      " 28%|██▊       | 70/252 [00:16<00:31,  5.75it/s]\n",
      " 28%|██▊       | 71/252 [00:16<00:36,  4.95it/s]\n",
      " 29%|██▊       | 72/252 [00:16<00:31,  5.63it/s]\n",
      " 29%|██▉       | 73/252 [00:17<00:42,  4.26it/s]\n",
      " 29%|██▉       | 74/252 [00:17<00:40,  4.43it/s]\n",
      " 30%|██▉       | 75/252 [00:17<00:33,  5.24it/s]\n",
      " 30%|███       | 76/252 [00:17<00:39,  4.50it/s]\n",
      " 31%|███       | 77/252 [00:17<00:32,  5.35it/s]\n",
      " 31%|███       | 78/252 [00:18<00:38,  4.54it/s]\n",
      " 31%|███▏      | 79/252 [00:18<00:37,  4.66it/s]\n",
      " 32%|███▏      | 80/252 [00:18<00:36,  4.76it/s]\n",
      " 33%|███▎      | 82/252 [00:18<00:27,  6.26it/s]\n",
      " 33%|███▎      | 83/252 [00:18<00:32,  5.14it/s]\n",
      " 33%|███▎      | 84/252 [00:19<00:28,  5.88it/s]\n",
      " 34%|███▎      | 85/252 [00:19<00:34,  4.87it/s]\n",
      " 35%|███▍      | 87/252 [00:19<00:37,  4.44it/s]\n",
      " 35%|███▍      | 88/252 [00:20<00:47,  3.44it/s]\n",
      " 35%|███▌      | 89/252 [00:20<00:43,  3.73it/s]\n",
      " 36%|███▌      | 90/252 [00:20<00:40,  4.00it/s]\n",
      " 36%|███▌      | 91/252 [00:21<00:42,  3.79it/s]\n",
      " 37%|███▋      | 92/252 [00:21<00:34,  4.59it/s]\n",
      " 37%|███▋      | 93/252 [00:21<00:33,  4.70it/s]\n",
      " 37%|███▋      | 94/252 [00:21<00:33,  4.78it/s]\n",
      " 38%|███▊      | 96/252 [00:21<00:32,  4.87it/s]\n",
      " 39%|███▉      | 98/252 [00:22<00:28,  5.45it/s]\n",
      " 39%|███▉      | 99/252 [00:22<00:28,  5.34it/s]\n",
      " 40%|███▉      | 100/252 [00:22<00:25,  6.00it/s]\n",
      " 40%|████      | 101/252 [00:23<00:37,  3.98it/s]\n",
      " 41%|████      | 103/252 [00:23<00:24,  5.99it/s]\n",
      " 41%|████▏     | 104/252 [00:23<00:25,  5.73it/s]\n",
      " 42%|████▏     | 105/252 [00:23<00:30,  4.86it/s]\n",
      " 42%|████▏     | 106/252 [00:23<00:29,  4.89it/s]\n",
      " 42%|████▏     | 107/252 [00:23<00:25,  5.68it/s]\n",
      " 43%|████▎     | 108/252 [00:24<00:30,  4.74it/s]\n",
      " 43%|████▎     | 109/252 [00:24<00:29,  4.81it/s]\n",
      " 44%|████▎     | 110/252 [00:24<00:25,  5.66it/s]\n",
      " 44%|████▍     | 111/252 [00:24<00:30,  4.69it/s]\n",
      " 44%|████▍     | 112/252 [00:25<00:29,  4.78it/s]\n",
      " 45%|████▍     | 113/252 [00:25<00:24,  5.65it/s]\n",
      " 45%|████▌     | 114/252 [00:25<00:33,  4.10it/s]\n",
      " 46%|████▌     | 115/252 [00:25<00:27,  4.98it/s]\n",
      " 46%|████▌     | 116/252 [00:26<00:35,  3.84it/s]\n",
      " 46%|████▋     | 117/252 [00:26<00:44,  3.01it/s]\n",
      " 47%|████▋     | 118/252 [00:26<00:39,  3.41it/s]\n",
      " 48%|████▊     | 121/252 [00:27<00:29,  4.50it/s]\n",
      " 48%|████▊     | 122/252 [00:27<00:28,  4.59it/s]\n",
      " 49%|████▉     | 123/252 [00:27<00:36,  3.53it/s]\n",
      " 50%|████▉     | 125/252 [00:28<00:24,  5.25it/s]\n",
      " 50%|█████     | 126/252 [00:28<00:35,  3.55it/s]\n",
      " 50%|█████     | 127/252 [00:28<00:29,  4.20it/s]\n",
      " 51%|█████     | 129/252 [00:28<00:19,  6.19it/s]\n",
      " 52%|█████▏    | 131/252 [00:29<00:25,  4.70it/s]\n",
      " 53%|█████▎    | 133/252 [00:29<00:20,  5.75it/s]\n",
      " 53%|█████▎    | 134/252 [00:29<00:23,  5.03it/s]\n",
      " 54%|█████▎    | 135/252 [00:30<00:31,  3.77it/s]\n",
      " 54%|█████▍    | 136/252 [00:30<00:26,  4.43it/s]\n",
      " 55%|█████▍    | 138/252 [00:30<00:24,  4.64it/s]\n",
      " 55%|█████▌    | 139/252 [00:31<00:21,  5.27it/s]\n",
      " 56%|█████▌    | 140/252 [00:31<00:21,  5.20it/s]\n",
      " 56%|█████▌    | 141/252 [00:31<00:21,  5.14it/s]\n",
      " 56%|█████▋    | 142/252 [00:31<00:18,  5.91it/s]\n",
      " 57%|█████▋    | 143/252 [00:31<00:25,  4.28it/s]\n",
      " 58%|█████▊    | 145/252 [00:32<00:23,  4.57it/s]\n",
      " 58%|█████▊    | 147/252 [00:32<00:20,  5.20it/s]\n",
      " 59%|█████▊    | 148/252 [00:32<00:20,  5.15it/s]\n",
      " 59%|█████▉    | 149/252 [00:33<00:22,  4.56it/s]\n",
      " 60%|█████▉    | 151/252 [00:33<00:17,  5.84it/s]\n",
      " 60%|██████    | 152/252 [00:33<00:15,  6.44it/s]\n",
      " 61%|██████    | 153/252 [00:34<00:26,  3.80it/s]\n",
      " 61%|██████    | 154/252 [00:34<00:21,  4.52it/s]\n",
      " 62%|██████▏   | 155/252 [00:34<00:18,  5.30it/s]\n",
      " 62%|██████▏   | 156/252 [00:34<00:15,  6.09it/s]\n",
      " 62%|██████▏   | 157/252 [00:34<00:16,  5.73it/s]\n",
      " 63%|██████▎   | 158/252 [00:34<00:19,  4.74it/s]\n",
      " 63%|██████▎   | 160/252 [00:35<00:18,  4.85it/s]\n",
      " 64%|██████▍   | 161/252 [00:35<00:20,  4.36it/s]\n",
      " 64%|██████▍   | 162/252 [00:35<00:19,  4.51it/s]\n",
      " 65%|██████▍   | 163/252 [00:36<00:21,  4.11it/s]\n",
      " 65%|██████▌   | 164/252 [00:36<00:17,  4.92it/s]\n",
      " 65%|██████▌   | 165/252 [00:36<00:20,  4.33it/s]\n",
      " 66%|██████▌   | 166/252 [00:36<00:19,  4.50it/s]\n",
      " 66%|██████▋   | 167/252 [00:36<00:18,  4.63it/s]\n",
      " 67%|██████▋   | 168/252 [00:37<00:17,  4.73it/s]\n",
      " 67%|██████▋   | 169/252 [00:37<00:19,  4.21it/s]\n",
      " 67%|██████▋   | 170/252 [00:37<00:23,  3.49it/s]\n",
      " 68%|██████▊   | 172/252 [00:38<00:16,  4.98it/s]\n",
      " 69%|██████▊   | 173/252 [00:38<00:19,  4.00it/s]\n",
      " 69%|██████▉   | 174/252 [00:38<00:16,  4.74it/s]\n",
      " 69%|██████▉   | 175/252 [00:38<00:16,  4.80it/s]\n",
      " 70%|██████▉   | 176/252 [00:38<00:15,  4.85it/s]\n",
      " 70%|███████   | 177/252 [00:39<00:17,  4.29it/s]\n",
      " 71%|███████   | 178/252 [00:39<00:14,  5.14it/s]\n",
      " 71%|███████   | 179/252 [00:39<00:16,  4.43it/s]\n",
      " 71%|███████▏  | 180/252 [00:39<00:15,  4.58it/s]\n",
      " 73%|███████▎  | 183/252 [00:40<00:09,  7.48it/s]\n",
      " 73%|███████▎  | 184/252 [00:40<00:11,  5.93it/s]\n",
      " 73%|███████▎  | 185/252 [00:40<00:13,  5.02it/s]\n",
      " 74%|███████▍  | 186/252 [00:40<00:11,  5.73it/s]\n",
      " 74%|███████▍  | 187/252 [00:40<00:10,  6.44it/s]\n",
      " 75%|███████▍  | 188/252 [00:41<00:12,  5.13it/s]\n",
      " 75%|███████▌  | 190/252 [00:41<00:09,  6.52it/s]\n",
      " 76%|███████▌  | 191/252 [00:41<00:08,  7.10it/s]\n",
      " 76%|███████▌  | 192/252 [00:41<00:07,  7.66it/s]\n",
      " 77%|███████▋  | 193/252 [00:42<00:15,  3.91it/s]\n",
      " 77%|███████▋  | 195/252 [00:42<00:09,  5.99it/s]\n",
      " 78%|███████▊  | 197/252 [00:42<00:11,  4.59it/s]\n",
      " 79%|███████▊  | 198/252 [00:43<00:12,  4.24it/s]\n",
      " 79%|███████▉  | 199/252 [00:43<00:13,  3.99it/s]\n",
      " 79%|███████▉  | 200/252 [00:43<00:11,  4.69it/s]\n",
      " 80%|████████  | 202/252 [00:44<00:11,  4.37it/s]\n",
      " 81%|████████  | 203/252 [00:44<00:09,  5.02it/s]\n",
      " 81%|████████  | 204/252 [00:44<00:10,  4.46it/s]\n",
      " 81%|████████▏ | 205/252 [00:44<00:09,  5.21it/s]\n",
      " 82%|████████▏ | 206/252 [00:44<00:11,  4.02it/s]\n",
      " 83%|████████▎ | 209/252 [00:45<00:06,  6.63it/s]\n",
      " 83%|████████▎ | 210/252 [00:45<00:06,  6.21it/s]\n",
      " 84%|████████▎ | 211/252 [00:45<00:07,  5.20it/s]\n",
      " 85%|████████▍ | 213/252 [00:45<00:05,  7.32it/s]\n",
      " 85%|████████▌ | 215/252 [00:46<00:09,  4.01it/s]\n",
      " 86%|████████▌ | 216/252 [00:46<00:07,  4.57it/s]\n",
      " 86%|████████▌ | 217/252 [00:46<00:07,  4.66it/s]\n",
      " 87%|████████▋ | 218/252 [00:47<00:07,  4.73it/s]\n",
      " 87%|████████▋ | 219/252 [00:47<00:06,  5.48it/s]\n",
      " 87%|████████▋ | 220/252 [00:47<00:05,  6.23it/s]\n",
      " 88%|████████▊ | 221/252 [00:47<00:06,  5.02it/s]\n",
      " 88%|████████▊ | 223/252 [00:47<00:04,  6.43it/s]\n",
      " 89%|████████▉ | 224/252 [00:48<00:06,  4.19it/s]\n",
      " 90%|████████▉ | 226/252 [00:48<00:04,  5.49it/s]\n",
      " 90%|█████████ | 227/252 [00:48<00:05,  4.32it/s]\n",
      " 90%|█████████ | 228/252 [00:49<00:04,  5.01it/s]\n",
      " 91%|█████████ | 229/252 [00:49<00:06,  3.30it/s]\n",
      " 91%|█████████▏| 230/252 [00:49<00:06,  3.63it/s]\n",
      " 92%|█████████▏| 232/252 [00:50<00:03,  5.02it/s]\n",
      " 92%|█████████▏| 233/252 [00:50<00:04,  4.48it/s]\n",
      " 93%|█████████▎| 234/252 [00:50<00:03,  5.21it/s]\n",
      " 93%|█████████▎| 235/252 [00:50<00:02,  5.96it/s]\n",
      " 94%|█████████▎| 236/252 [00:50<00:02,  5.66it/s]\n",
      " 94%|█████████▍| 237/252 [00:50<00:02,  5.45it/s]\n",
      " 94%|█████████▍| 238/252 [00:51<00:03,  3.64it/s]\n",
      " 95%|█████████▌| 240/252 [00:51<00:02,  5.10it/s]\n",
      " 96%|█████████▌| 241/252 [00:51<00:01,  5.79it/s]\n",
      " 96%|█████████▌| 242/252 [00:52<00:02,  4.32it/s]\n",
      " 96%|█████████▋| 243/252 [00:52<00:02,  4.48it/s]\n",
      " 97%|█████████▋| 244/252 [00:52<00:01,  4.61it/s]\n",
      " 97%|█████████▋| 245/252 [00:52<00:01,  4.71it/s]\n",
      " 98%|█████████▊| 246/252 [00:52<00:01,  5.56it/s]\n",
      " 98%|█████████▊| 247/252 [00:53<00:01,  3.66it/s]\n",
      " 99%|█████████▉| 249/252 [00:53<00:00,  5.82it/s]\n",
      " 99%|█████████▉| 250/252 [00:53<00:00,  4.92it/s]\n",
      "100%|█████████▉| 251/252 [00:53<00:00,  5.66it/s]\n",
      "100%|██████████| 252/252 [00:53<00:00,  6.41it/s]\n",
      "100%|██████████| 252/252 [00:54<00:00,  4.66it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the preprocessed dataset\n",
    "import subprocess\n",
    "\n",
    "env_vars = os.environ.copy()\n",
    "# print(root_dir)\n",
    "env_vars['nnUNet_raw'] = \"/mnt/data/gpu-server/m31_nnUnet/nnunet_data/nnUNet_raw\"\n",
    "env_vars['nnUNet_preprocessed'] = \"/mnt/data/gpu-server/m31_nnUnet/nnunet_data/nnUNet_preprocessed\"\n",
    "env_vars['nnUNet_results'] = \"/mnt/data/gpu-server/m31_nnUnet/nnunet_data/nnUNet_results\"\n",
    "\n",
    "\n",
    "\n",
    "result = subprocess.run([\n",
    "    \"uv\", \"run\", \"--extra\", \"cu124\",\n",
    "    \"nnUNetv2_plan_and_preprocess\",\n",
    "    # \"-pl\", \"nnUNetPlannerResEncM\", # use without to use default planner\n",
    "    \"-d\", \"1\",\n",
    "    \"-c\", \"3d_fullres\",\n",
    "    \"-npfp\", \"8\",\n",
    "    \"--verify_dataset_integrity\"\n",
    "], env=env_vars, capture_output=True, text=True, check=True)\n",
    "\n",
    "print(\"STDOUT:\", result.stdout)\n",
    "print(\"STDERR:\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create split_final.json to specify training and validation split\n",
    "# split_final = {\n",
    "#     \"train\": [],\n",
    "#     \"val\": []\n",
    "# }\n",
    "# for key, value in labels.items():\n",
    "#     if value[\"split\"] == \"train\":\n",
    "#         split_final[\"train\"].append(key.split('.')[0])\n",
    "#     elif value[\"split\"] == \"validation\":\n",
    "#         split_final[\"val\"].append(key.split('.')[0])\n",
    "# with open(os.path.join(root_dir, \"nnUNet_preprocessed\", \"Dataset001_PancreasSegClassification\", \"split_final.json\"), \"w\") as jsonfile:\n",
    "#     json.dump([split_final], jsonfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc6f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intuition check on the data\n",
    "# from batchgenerators.utilities.file_and_folder_operations import load_json\n",
    "# splits = load_json(\"/mnt/data/gpu-server/m31_nnUnet/nnunet_data/nnUNet_preprocessed/Dataset001_PancreasSegClassification/split_final.json\")\n",
    "# assert len(splits[0]['train']) + len(splits[0]['val']) == 288, \"Total number of cases should be 288.\"\n",
    "\n",
    "# # check total number of cases in saved under proprocessed directory\n",
    "# len(os.listdir(\"/mnt/data/gpu-server/m31_nnUnet/nnunet_data/nnUNet_preprocessed/Dataset001_PancreasSegClassification/gt_segmentations\"))\n",
    "# assert len(os.listdir(os.path.join(root_dir, \"nnUNet_preprocessed\", \"Dataset001_PancreasSegClassification\", \"imagesTr\"))) == 288, \"Number of images in imagesTr should be 288.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
